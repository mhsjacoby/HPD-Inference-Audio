{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 1000, 16)\n",
      "(397, 1000, 16)\n",
      "(458, 1000, 16)\n",
      "(323, 1000, 16)\n",
      "(496, 1000, 16)\n",
      "(300, 1000, 16)\n",
      "(303, 1000, 16)\n",
      "(322, 1000, 16)\n",
      "(323, 1000, 16)\n",
      "(410, 1000, 16)\n"
     ]
    }
   ],
   "source": [
    "path1 = '/Users/maggie/Documents/Github/HPD-Inference_and_Processing/Audio/Inference-Audio/Audio_CNN/H1-red/processed/'\n",
    "\n",
    "x = 0\n",
    "for numpy_file in glob(os.path.join(path1, '*.npy')):\n",
    "    data = np.load(numpy_file)\n",
    "    print(np.shape(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347, 16, 1000)\n",
      "(350, 16, 1000)\n",
      "(332, 16, 1000)\n",
      "(329, 16, 1000)\n",
      "(359, 16, 1000)\n",
      "(329, 16, 1000)\n",
      "(329, 16, 1000)\n",
      "(354, 16, 1000)\n",
      "(309, 16, 1000)\n",
      "(344, 16, 1000)\n",
      "(318, 16, 1000)\n",
      "(328, 16, 1000)\n",
      "(348, 16, 1000)\n",
      "(359, 16, 1000)\n",
      "(360, 16, 1000)\n",
      "(347, 16, 1000)\n",
      "(348, 16, 1000)\n",
      "(358, 16, 1000)\n",
      "(348, 16, 1000)\n",
      "(351, 16, 1000)\n",
      "(329, 16, 1000)\n",
      "(359, 16, 1000)\n",
      "(348, 16, 1000)\n",
      "(345, 16, 1000)\n"
     ]
    }
   ],
   "source": [
    "path2 = '/Volumes/TOSHIBA-21/H1-red/RS1/processed_audio/audio_downsampled/2019-11-06/'\n",
    "\n",
    "for npz in glob(os.path.join(path2, '*.npz')):\n",
    "    hour = os.path.basename(npz).split('_')[1]\n",
    "    full_hr = np.load(npz)\n",
    "#     print(type(audio_data.files))\n",
    "    times = full_hr.files\n",
    "    time_keys, audio_data = [], []\n",
    "    for time in times:\n",
    "        if len(full_hr[time]) > 0:\n",
    "            time_keys.append(time)\n",
    "            audio_data.append(full_hr[time])\n",
    "\n",
    "    data = np.stack(audio_data)\n",
    "    data = data.transpose(0,2,1)\n",
    "    print(np.shape(data))\n",
    "\n",
    "#         print(time, np.shape(audio_data[time]))\n",
    "#     data = [audio_data[time] for time in times if len(audio_data[time]>0)]\n",
    "#     print(np.shape(np.stack(data)))\n",
    "    \n",
    "    \n",
    "#     for t in times:\n",
    "#         print(type(t), t)\n",
    "# #     print(time_keys)\n",
    "    \n",
    "#     \n",
    "#     for time in times:\n",
    "#         ds = np.asarray([audio_data[time]])\n",
    "#         dst = ds.transpose(0,2,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         keys = np.fromiter(Samples.keys(), dtype=float)\n",
    "# vals = np.fromiter(Samples.values(), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        hour = os.path.basename(npz).split('_')[1]\n",
    "        audio_data = np.load(npz)\n",
    "        times = audio_data.files\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for time in times:\n",
    "            DCTs = audio_data[time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_npz(noise_file, path, audio_type='ds'):\n",
    "    home = os.path.basename(path).split('-')[0]\n",
    "    hub, day, time, action = get_title(noise_file).split(' ')\n",
    "\n",
    "    file = f'{day}_{str(time[0:2])}00_{hub}_{home}_{audio_type}.npz'\n",
    "    npz = os.path.join(path, hub, 'processed_audio', ps_type[audio_type], day, file)\n",
    "    data = np.load(npz)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 13, 997, 32)       544       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 996, 16)       2064      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 191232)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 382466    \n",
      "=================================================================\n",
      "Total params: 385,074\n",
      "Trainable params: 385,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path = '/Users/maggie/Documents/Github/HPD-Inference_and_Processing/Audio/Inference-Audio/'\n",
    "model = model_from_json(open(os.path.join(model_path, 'Audio_CNN/model-94_96/CNN_model.json')).read())\n",
    "model.load_weights(os.path.join(model_path, 'Audio_CNN/model-94_96/CNN_weights.h5'))\n",
    "model.summary()\n",
    "scaler = pickle.load(open(os.path.join(model_path, 'Audio_CNN/model-94_96/scaler.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have shape (16, 1000, 1) but got array with shape (1000, 16, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-26578b9102c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mperform_inf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-26578b9102c7>\u001b[0m in \u001b[0;36mperform_inf\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_input_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_input_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mclass_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclass_prob\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 715\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    716\u001b[0m     return predict_loop(\n\u001b[1;32m    717\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have shape (16, 1000, 1) but got array with shape (1000, 16, 1)"
     ]
    }
   ],
   "source": [
    "# movement1 = '/Users/maggie/Desktop/plot_audio/filter_output/RS1-noise.npy'\n",
    "# noSound = '/Users/maggie/Desktop/plot_audio/filter_output/RS1-quiet.npy'\n",
    "\n",
    "f1 = '/Users/maggie/Documents/Github/HPD-Inference_and_Processing/Audio/Inference-Audio/Audio_CNN/CNN_testing_code/H1-red/processed/RS1-noise.npy'\n",
    "\n",
    "\n",
    "def perform_inf(path):\n",
    "    input_data = np.load(path) \n",
    "    input_data = np.transpose()\n",
    "    ori_input_shape = input_data.shape\n",
    "    input_data = input_data.reshape((len(input_data), -1))\n",
    "    input_data = scaler.transform(input_data)\n",
    "    input_data = input_data.reshape((len(input_data), ori_input_shape[1], ori_input_shape[2], 1))\n",
    "\n",
    "    class_prob = model.predict(input_data)\n",
    "    probabilities = class_prob[:,1]\n",
    "    predictions = (class_prob>0.5).astype(\"int32\")\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    print(probabilities, predictions)\n",
    "    \n",
    "perform_inf(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
